<html>
<head>
<title>test_managed_alloc.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #7a7e85;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_managed_alloc.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">ctypes </span><span class="s0">import </span><span class="s1">byref</span><span class="s2">, </span><span class="s1">c_size_t</span>
<span class="s0">from </span><span class="s1">numba</span><span class="s2">.</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">cudadrv</span><span class="s2">.</span><span class="s1">driver </span><span class="s0">import </span><span class="s1">device_memset</span><span class="s2">, </span><span class="s1">driver</span><span class="s2">, </span><span class="s1">USE_NV_BINDING</span>
<span class="s0">from </span><span class="s1">numba </span><span class="s0">import </span><span class="s1">cuda</span>
<span class="s0">from </span><span class="s1">numba</span><span class="s2">.</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">testing </span><span class="s0">import </span><span class="s1">unittest</span><span class="s2">, </span><span class="s1">ContextResettingTestCase</span>
<span class="s0">from </span><span class="s1">numba</span><span class="s2">.</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">testing </span><span class="s0">import </span><span class="s1">skip_on_cudasim</span><span class="s2">, </span><span class="s1">skip_on_arm</span>
<span class="s0">from </span><span class="s1">numba</span><span class="s2">.</span><span class="s1">tests</span><span class="s2">.</span><span class="s1">support </span><span class="s0">import </span><span class="s1">linux_only</span>


<span class="s2">@</span><span class="s1">skip_on_cudasim</span><span class="s2">(</span><span class="s3">'CUDA Driver API unsupported in the simulator'</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">linux_only</span>
<span class="s2">@</span><span class="s1">skip_on_arm</span><span class="s2">(</span><span class="s3">'Managed Alloc support is experimental/untested on ARM'</span><span class="s2">)</span>
<span class="s0">class </span><span class="s1">TestManagedAlloc</span><span class="s2">(</span><span class="s1">ContextResettingTestCase</span><span class="s2">):</span>

    <span class="s0">def </span><span class="s1">get_total_gpu_memory</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s4"># We use a driver function to directly get the total GPU memory because</span>
        <span class="s4"># an EMM plugin may report something different (or not implement</span>
        <span class="s4"># get_memory_info at all).</span>
        <span class="s0">if </span><span class="s1">USE_NV_BINDING</span><span class="s2">:</span>
            <span class="s1">free</span><span class="s2">, </span><span class="s1">total </span><span class="s2">= </span><span class="s1">driver</span><span class="s2">.</span><span class="s1">cuMemGetInfo</span><span class="s2">()</span>
            <span class="s0">return </span><span class="s1">total</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">free </span><span class="s2">= </span><span class="s1">c_size_t</span><span class="s2">()</span>
            <span class="s1">total </span><span class="s2">= </span><span class="s1">c_size_t</span><span class="s2">()</span>
            <span class="s1">driver</span><span class="s2">.</span><span class="s1">cuMemGetInfo</span><span class="s2">(</span><span class="s1">byref</span><span class="s2">(</span><span class="s1">free</span><span class="s2">), </span><span class="s1">byref</span><span class="s2">(</span><span class="s1">total</span><span class="s2">))</span>
            <span class="s0">return </span><span class="s1">total</span><span class="s2">.</span><span class="s1">value</span>

    <span class="s0">def </span><span class="s1">skip_if_cc_major_lt</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">min_required</span><span class="s2">, </span><span class="s1">reason</span><span class="s2">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Skip the current test if the compute capability of the device is 
        less than `min_required`. 
        &quot;&quot;&quot;</span>
        <span class="s1">ctx </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">current_context</span><span class="s2">()</span>
        <span class="s1">cc_major </span><span class="s2">= </span><span class="s1">ctx</span><span class="s2">.</span><span class="s1">device</span><span class="s2">.</span><span class="s1">compute_capability</span><span class="s2">[</span><span class="s6">0</span><span class="s2">]</span>
        <span class="s0">if </span><span class="s1">cc_major </span><span class="s2">&lt; </span><span class="s1">min_required</span><span class="s2">:</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">skipTest</span><span class="s2">(</span><span class="s1">reason</span><span class="s2">)</span>

    <span class="s4"># CUDA Unified Memory comes in two flavors. For GPUs in the Kepler and</span>
    <span class="s4"># Maxwell generations, managed memory allocations work as opaque,</span>
    <span class="s4"># contiguous segments that can either be on the device or the host. For</span>
    <span class="s4"># GPUs in the Pascal or later generations, managed memory operates on a</span>
    <span class="s4"># per-page basis, so we can have arrays larger than GPU memory, where only</span>
    <span class="s4"># part of them is resident on the device at one time. To ensure that this</span>
    <span class="s4"># test works correctly on all supported GPUs, we'll select the size of our</span>
    <span class="s4"># memory such that we only oversubscribe the GPU memory if we're on a</span>
    <span class="s4"># Pascal or newer GPU (compute capability at least 6.0).</span>

    <span class="s0">def </span><span class="s1">test_managed_alloc_driver_undersubscribe</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Managed memory unsupported prior to CC 3.0&quot;</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">skip_if_cc_major_lt</span><span class="s2">(</span><span class="s6">3</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_test_managed_alloc_driver</span><span class="s2">(</span><span class="s6">0.5</span><span class="s2">)</span>

    <span class="s4"># This test is skipped by default because it is easy to hang the machine</span>
    <span class="s4"># for a very long time or get OOM killed if the GPU memory size is &gt;50% of</span>
    <span class="s4"># the system memory size. Even if the system does have more than 2x the RAM</span>
    <span class="s4"># of the GPU, this test runs for a very long time (in comparison to the</span>
    <span class="s4"># rest of the tests in the suite).</span>
    <span class="s4">#</span>
    <span class="s4"># However, it is left in here for manual testing as required.</span>

    <span class="s2">@</span><span class="s1">unittest</span><span class="s2">.</span><span class="s1">skip</span>
    <span class="s0">def </span><span class="s1">test_managed_alloc_driver_oversubscribe</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Oversubscription of managed memory unsupported prior to CC 6.0&quot;</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">skip_if_cc_major_lt</span><span class="s2">(</span><span class="s6">6</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_test_managed_alloc_driver</span><span class="s2">(</span><span class="s6">2.0</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">test_managed_alloc_driver_host_attach</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Host attached managed memory is not accessible prior to CC 6.0&quot;</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">skip_if_cc_major_lt</span><span class="s2">(</span><span class="s6">6</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">)</span>
        <span class="s4"># Only test with a small array (0.01 * memory size) to keep the test</span>
        <span class="s4"># quick.</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_test_managed_alloc_driver</span><span class="s2">(</span><span class="s6">0.01</span><span class="s2">, </span><span class="s1">attach_global</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">_test_managed_alloc_driver</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">memory_factor</span><span class="s2">, </span><span class="s1">attach_global</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
        <span class="s4"># Verify that we can allocate and operate on managed</span>
        <span class="s4"># memory through the CUDA driver interface.</span>

        <span class="s1">total_mem_size </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">get_total_gpu_memory</span><span class="s2">()</span>
        <span class="s1">n_bytes </span><span class="s2">= </span><span class="s1">int</span><span class="s2">(</span><span class="s1">memory_factor </span><span class="s2">* </span><span class="s1">total_mem_size</span><span class="s2">)</span>

        <span class="s1">ctx </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">current_context</span><span class="s2">()</span>
        <span class="s1">mem </span><span class="s2">= </span><span class="s1">ctx</span><span class="s2">.</span><span class="s1">memallocmanaged</span><span class="s2">(</span><span class="s1">n_bytes</span><span class="s2">, </span><span class="s1">attach_global</span><span class="s2">=</span><span class="s1">attach_global</span><span class="s2">)</span>

        <span class="s1">dtype </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">uint8</span><span class="s2">)</span>
        <span class="s1">n_elems </span><span class="s2">= </span><span class="s1">n_bytes </span><span class="s2">// </span><span class="s1">dtype</span><span class="s2">.</span><span class="s1">itemsize</span>
        <span class="s1">ary </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">n_elems</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">buffer</span><span class="s2">=</span><span class="s1">mem</span><span class="s2">)</span>

        <span class="s1">magic </span><span class="s2">= </span><span class="s6">0xab</span>
        <span class="s1">device_memset</span><span class="s2">(</span><span class="s1">mem</span><span class="s2">, </span><span class="s1">magic</span><span class="s2">, </span><span class="s1">n_bytes</span><span class="s2">)</span>
        <span class="s1">ctx</span><span class="s2">.</span><span class="s1">synchronize</span><span class="s2">()</span>

        <span class="s4"># Note that this assertion operates on the CPU, so this</span>
        <span class="s4"># test effectively drives both the CPU and the GPU on</span>
        <span class="s4"># managed memory.</span>

        <span class="s1">self</span><span class="s2">.</span><span class="s1">assertTrue</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">ary </span><span class="s2">== </span><span class="s1">magic</span><span class="s2">))</span>

    <span class="s0">def </span><span class="s1">_test_managed_array</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">attach_global</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
        <span class="s4"># Check the managed_array interface on both host and device.</span>

        <span class="s1">ary </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">managed_array</span><span class="s2">(</span><span class="s6">100</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">double</span><span class="s2">)</span>
        <span class="s1">ary</span><span class="s2">.</span><span class="s1">fill</span><span class="s2">(</span><span class="s6">123.456</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">assertTrue</span><span class="s2">(</span><span class="s1">all</span><span class="s2">(</span><span class="s1">ary </span><span class="s2">== </span><span class="s6">123.456</span><span class="s2">))</span>

        <span class="s2">@</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">jit</span><span class="s2">(</span><span class="s3">'void(double[:])'</span><span class="s2">)</span>
        <span class="s0">def </span><span class="s1">kernel</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
            <span class="s1">i </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">grid</span><span class="s2">(</span><span class="s6">1</span><span class="s2">)</span>
            <span class="s0">if </span><span class="s1">i </span><span class="s2">&lt; </span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s6">0</span><span class="s2">]:</span>
                <span class="s1">x</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] = </span><span class="s6">1.0</span>

        <span class="s1">kernel</span><span class="s2">[</span><span class="s6">10</span><span class="s2">, </span><span class="s6">10</span><span class="s2">](</span><span class="s1">ary</span><span class="s2">)</span>
        <span class="s1">cuda</span><span class="s2">.</span><span class="s1">current_context</span><span class="s2">().</span><span class="s1">synchronize</span><span class="s2">()</span>

        <span class="s1">self</span><span class="s2">.</span><span class="s1">assertTrue</span><span class="s2">(</span><span class="s1">all</span><span class="s2">(</span><span class="s1">ary </span><span class="s2">== </span><span class="s6">1.0</span><span class="s2">))</span>

    <span class="s0">def </span><span class="s1">test_managed_array_attach_global</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_test_managed_array</span><span class="s2">()</span>

    <span class="s0">def </span><span class="s1">test_managed_array_attach_host</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_test_managed_array</span><span class="s2">()</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Host attached managed memory is not accessible prior to CC 6.0&quot;</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">skip_if_cc_major_lt</span><span class="s2">(</span><span class="s6">6</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_test_managed_array</span><span class="s2">(</span><span class="s1">attach_global</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>


<span class="s0">if </span><span class="s1">__name__ </span><span class="s2">== </span><span class="s3">'__main__'</span><span class="s2">:</span>
    <span class="s1">unittest</span><span class="s2">.</span><span class="s1">main</span><span class="s2">()</span>
</pre>
</body>
</html>