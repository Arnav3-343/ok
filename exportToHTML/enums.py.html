<html>
<head>
<title>enums.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #bcbec4;}
.s4 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
enums.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Enum values for CUDA driver. Information about the values 
can be found on the official NVIDIA documentation website. 
ref: https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html 
anchor: #group__CUDA__TYPES 
&quot;&quot;&quot;</span>


<span class="s2"># Error codes</span>

<span class="s1">CUDA_SUCCESS </span><span class="s3">= </span><span class="s4">0</span>
<span class="s1">CUDA_ERROR_INVALID_VALUE </span><span class="s3">= </span><span class="s4">1</span>
<span class="s1">CUDA_ERROR_OUT_OF_MEMORY </span><span class="s3">= </span><span class="s4">2</span>
<span class="s1">CUDA_ERROR_NOT_INITIALIZED </span><span class="s3">= </span><span class="s4">3</span>
<span class="s1">CUDA_ERROR_DEINITIALIZED </span><span class="s3">= </span><span class="s4">4</span>
<span class="s1">CUDA_ERROR_PROFILER_DISABLED </span><span class="s3">= </span><span class="s4">5</span>
<span class="s1">CUDA_ERROR_PROFILER_NOT_INITIALIZED </span><span class="s3">= </span><span class="s4">6</span>
<span class="s1">CUDA_ERROR_PROFILER_ALREADY_STARTED </span><span class="s3">= </span><span class="s4">7</span>
<span class="s1">CUDA_ERROR_PROFILER_ALREADY_STOPPED </span><span class="s3">= </span><span class="s4">8</span>
<span class="s1">CUDA_ERROR_STUB_LIBRARY </span><span class="s3">= </span><span class="s4">34</span>
<span class="s1">CUDA_ERROR_DEVICE_UNAVAILABLE </span><span class="s3">= </span><span class="s4">46</span>
<span class="s1">CUDA_ERROR_NO_DEVICE </span><span class="s3">= </span><span class="s4">100</span>
<span class="s1">CUDA_ERROR_INVALID_DEVICE </span><span class="s3">= </span><span class="s4">101</span>
<span class="s1">CUDA_ERROR_DEVICE_NOT_LICENSED </span><span class="s3">= </span><span class="s4">102</span>
<span class="s1">CUDA_ERROR_INVALID_IMAGE </span><span class="s3">= </span><span class="s4">200</span>
<span class="s1">CUDA_ERROR_INVALID_CONTEXT </span><span class="s3">= </span><span class="s4">201</span>
<span class="s1">CUDA_ERROR_CONTEXT_ALREADY_CURRENT </span><span class="s3">= </span><span class="s4">202</span>
<span class="s1">CUDA_ERROR_MAP_FAILED </span><span class="s3">= </span><span class="s4">205</span>
<span class="s1">CUDA_ERROR_UNMAP_FAILED </span><span class="s3">= </span><span class="s4">206</span>
<span class="s1">CUDA_ERROR_ARRAY_IS_MAPPED </span><span class="s3">= </span><span class="s4">207</span>
<span class="s1">CUDA_ERROR_ALREADY_MAPPED </span><span class="s3">= </span><span class="s4">208</span>
<span class="s1">CUDA_ERROR_NO_BINARY_FOR_GPU </span><span class="s3">= </span><span class="s4">209</span>
<span class="s1">CUDA_ERROR_ALREADY_ACQUIRED </span><span class="s3">= </span><span class="s4">210</span>
<span class="s1">CUDA_ERROR_NOT_MAPPED </span><span class="s3">= </span><span class="s4">211</span>
<span class="s1">CUDA_ERROR_NOT_MAPPED_AS_ARRAY </span><span class="s3">= </span><span class="s4">212</span>
<span class="s1">CUDA_ERROR_NOT_MAPPED_AS_POINTER </span><span class="s3">= </span><span class="s4">213</span>
<span class="s1">CUDA_ERROR_ECC_UNCORRECTABLE </span><span class="s3">= </span><span class="s4">214</span>
<span class="s1">CUDA_ERROR_UNSUPPORTED_LIMIT </span><span class="s3">= </span><span class="s4">215</span>
<span class="s1">CUDA_ERROR_CONTEXT_ALREADY_IN_USE </span><span class="s3">= </span><span class="s4">216</span>
<span class="s1">CUDA_ERROR_PEER_ACCESS_UNSUPPORTED </span><span class="s3">= </span><span class="s4">217</span>
<span class="s1">CUDA_ERROR_INVALID_PTX </span><span class="s3">= </span><span class="s4">218</span>
<span class="s1">CUDA_ERROR_INVALID_GRAPHICS_CONTEXT </span><span class="s3">= </span><span class="s4">219</span>
<span class="s1">CUDA_ERROR_NVLINK_UNCORRECTABLE </span><span class="s3">= </span><span class="s4">220</span>
<span class="s1">CUDA_ERROR_JIT_COMPILER_NOT_FOUND </span><span class="s3">= </span><span class="s4">221</span>
<span class="s1">CUDA_ERROR_UNSUPPORTED_PTX_VERSION </span><span class="s3">= </span><span class="s4">222</span>
<span class="s1">CUDA_ERROR_JIT_COMPILATION_DISABLED </span><span class="s3">= </span><span class="s4">223</span>
<span class="s1">CUDA_ERROR_UNSUPPORTED_EXEC_AFFINITY </span><span class="s3">= </span><span class="s4">224</span>
<span class="s1">CUDA_ERROR_UNSUPPORTED_DEVSIDE_SYNC </span><span class="s3">= </span><span class="s4">225</span>
<span class="s1">CUDA_ERROR_INVALID_SOURCE </span><span class="s3">= </span><span class="s4">300</span>
<span class="s1">CUDA_ERROR_FILE_NOT_FOUND </span><span class="s3">= </span><span class="s4">301</span>
<span class="s1">CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND </span><span class="s3">= </span><span class="s4">302</span>
<span class="s1">CUDA_ERROR_SHARED_OBJECT_INIT_FAILED </span><span class="s3">= </span><span class="s4">303</span>
<span class="s1">CUDA_ERROR_OPERATING_SYSTEM </span><span class="s3">= </span><span class="s4">304</span>
<span class="s1">CUDA_ERROR_INVALID_HANDLE </span><span class="s3">= </span><span class="s4">400</span>
<span class="s1">CUDA_ERROR_ILLEGAL_STATE </span><span class="s3">= </span><span class="s4">401</span>
<span class="s1">CUDA_ERROR_NOT_FOUND </span><span class="s3">= </span><span class="s4">500</span>
<span class="s1">CUDA_ERROR_NOT_READY </span><span class="s3">= </span><span class="s4">600</span>
<span class="s1">CUDA_ERROR_LAUNCH_FAILED </span><span class="s3">= </span><span class="s4">700</span>
<span class="s1">CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES </span><span class="s3">= </span><span class="s4">701</span>
<span class="s1">CUDA_ERROR_LAUNCH_TIMEOUT </span><span class="s3">= </span><span class="s4">702</span>
<span class="s1">CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING </span><span class="s3">= </span><span class="s4">703</span>
<span class="s1">CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED </span><span class="s3">= </span><span class="s4">704</span>
<span class="s1">CUDA_ERROR_PEER_ACCESS_NOT_ENABLED </span><span class="s3">= </span><span class="s4">705</span>
<span class="s1">CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE </span><span class="s3">= </span><span class="s4">708</span>
<span class="s1">CUDA_ERROR_CONTEXT_IS_DESTROYED </span><span class="s3">= </span><span class="s4">709</span>
<span class="s1">CUDA_ERROR_ASSERT </span><span class="s3">= </span><span class="s4">710</span>
<span class="s1">CUDA_ERROR_TOO_MANY_PEERS </span><span class="s3">= </span><span class="s4">711</span>
<span class="s1">CUDA_ERROR_HOST_MEMORY_ALREADY_REGISTERED </span><span class="s3">= </span><span class="s4">712</span>
<span class="s1">CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED </span><span class="s3">= </span><span class="s4">713</span>
<span class="s1">CUDA_ERROR_HARDWARE_STACK_ERROR </span><span class="s3">= </span><span class="s4">714</span>
<span class="s1">CUDA_ERROR_ILLEGAL_INSTRUCTION </span><span class="s3">= </span><span class="s4">715</span>
<span class="s1">CUDA_ERROR_MISALIGNED_ADDRESS </span><span class="s3">= </span><span class="s4">716</span>
<span class="s1">CUDA_ERROR_INVALID_ADDRESS_SPACE </span><span class="s3">= </span><span class="s4">717</span>
<span class="s1">CUDA_ERROR_INVALID_PC </span><span class="s3">= </span><span class="s4">718</span>
<span class="s1">CUDA_ERROR_LAUNCH_FAILED </span><span class="s3">= </span><span class="s4">719</span>
<span class="s1">CUDA_ERROR_COOPERATIVE_LAUNCH_TOO_LARGE </span><span class="s3">= </span><span class="s4">720</span>
<span class="s1">CUDA_ERROR_NOT_PERMITTED </span><span class="s3">= </span><span class="s4">800</span>
<span class="s1">CUDA_ERROR_NOT_SUPPORTED </span><span class="s3">= </span><span class="s4">801</span>
<span class="s1">CUDA_ERROR_SYSTEM_NOT_READY </span><span class="s3">= </span><span class="s4">802</span>
<span class="s1">CUDA_ERROR_SYSTEM_DRIVER_MISMATCH </span><span class="s3">= </span><span class="s4">803</span>
<span class="s1">CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE </span><span class="s3">= </span><span class="s4">804</span>
<span class="s1">CUDA_ERROR_MPS_CONNECTION_FAILED </span><span class="s3">= </span><span class="s4">805</span>
<span class="s1">CUDA_ERROR_MPS_RPC_FAILURE </span><span class="s3">= </span><span class="s4">806</span>
<span class="s1">CUDA_ERROR_MPS_SERVER_NOT_READY </span><span class="s3">= </span><span class="s4">807</span>
<span class="s1">CUDA_ERROR_MPS_MAX_CLIENTS_REACHED </span><span class="s3">= </span><span class="s4">808</span>
<span class="s1">CUDA_ERROR_MPS_MAX_CONNECTIONS_REACHED </span><span class="s3">= </span><span class="s4">809</span>
<span class="s1">CUDA_ERROR_MPS_CLIENT_TERMINATED </span><span class="s3">= </span><span class="s4">810</span>
<span class="s1">CUDA_ERROR_CDP_NOT_SUPPORTED </span><span class="s3">= </span><span class="s4">811</span>
<span class="s1">CUDA_ERROR_CDP_VERSION_MISMATCH </span><span class="s3">= </span><span class="s4">812</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_UNSUPPORTED </span><span class="s3">= </span><span class="s4">900</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_INVALIDATED </span><span class="s3">= </span><span class="s4">901</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_MERGE </span><span class="s3">= </span><span class="s4">902</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_UNMATCHED </span><span class="s3">= </span><span class="s4">903</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_UNJOINED </span><span class="s3">= </span><span class="s4">904</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_ISOLATION </span><span class="s3">= </span><span class="s4">905</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_IMPLICIT </span><span class="s3">= </span><span class="s4">906</span>
<span class="s1">CUDA_ERROR_CAPTURED_EVENT </span><span class="s3">= </span><span class="s4">907</span>
<span class="s1">CUDA_ERROR_STREAM_CAPTURE_WRONG_THREAD </span><span class="s3">= </span><span class="s4">908</span>
<span class="s1">CUDA_ERROR_TIMEOUT </span><span class="s3">= </span><span class="s4">909</span>
<span class="s1">CUDA_ERROR_GRAPH_EXEC_UPDATE_FAILURE </span><span class="s3">= </span><span class="s4">910</span>
<span class="s1">CUDA_ERROR_EXTERNAL_DEVICE </span><span class="s3">= </span><span class="s4">911</span>
<span class="s1">CUDA_ERROR_INVALID_CLUSTER_SIZE </span><span class="s3">= </span><span class="s4">912</span>
<span class="s1">CUDA_ERROR_UNKNOWN </span><span class="s3">= </span><span class="s4">999</span>


<span class="s2"># Function cache configurations</span>

<span class="s2"># no preference for shared memory or L1 (default)</span>
<span class="s1">CU_FUNC_CACHE_PREFER_NONE </span><span class="s3">= </span><span class="s4">0x00</span>
<span class="s2"># prefer larger shared memory and smaller L1 cache</span>
<span class="s1">CU_FUNC_CACHE_PREFER_SHARED </span><span class="s3">= </span><span class="s4">0x01</span>
<span class="s2"># prefer larger L1 cache and smaller shared memory</span>
<span class="s1">CU_FUNC_CACHE_PREFER_L1 </span><span class="s3">= </span><span class="s4">0x02</span>
<span class="s2"># prefer equal sized L1 cache and shared memory</span>
<span class="s1">CU_FUNC_CACHE_PREFER_EQUAL </span><span class="s3">= </span><span class="s4">0x03</span>


<span class="s2"># Context creation flags</span>

<span class="s2"># Automatic scheduling</span>
<span class="s1">CU_CTX_SCHED_AUTO </span><span class="s3">= </span><span class="s4">0x00</span>
<span class="s2"># Set spin as default scheduling</span>
<span class="s1">CU_CTX_SCHED_SPIN </span><span class="s3">= </span><span class="s4">0x01</span>
<span class="s2"># Set yield as default scheduling</span>
<span class="s1">CU_CTX_SCHED_YIELD </span><span class="s3">= </span><span class="s4">0x02</span>
<span class="s2"># Set blocking synchronization as default scheduling</span>
<span class="s1">CU_CTX_SCHED_BLOCKING_SYNC </span><span class="s3">= </span><span class="s4">0x04</span>

<span class="s1">CU_CTX_SCHED_MASK </span><span class="s3">= </span><span class="s4">0x07</span>
<span class="s2"># Support mapped pinned allocations</span>
<span class="s2">#   This flag was deprecated as of CUDA 11.0 and it no longer has effect.</span>
<span class="s2">#   All contexts as of CUDA 3.2 behave as though the flag is enabled.</span>
<span class="s1">CU_CTX_MAP_HOST </span><span class="s3">= </span><span class="s4">0x08</span>
<span class="s2"># Keep local memory allocation after launch</span>
<span class="s1">CU_CTX_LMEM_RESIZE_TO_MAX </span><span class="s3">= </span><span class="s4">0x10</span>
<span class="s2"># Trigger coredumps from exceptions in this context</span>
<span class="s1">CU_CTX_COREDUMP_ENABLE </span><span class="s3">= </span><span class="s4">0x20</span>
<span class="s2"># Enable user pipe to trigger coredumps in this context</span>
<span class="s1">CU_CTX_USER_COREDUMP_ENABLE </span><span class="s3">= </span><span class="s4">0x40</span>
<span class="s2"># Force synchronous blocking on cudaMemcpy/cudaMemset</span>
<span class="s1">CU_CTX_SYNC_MEMOPS </span><span class="s3">= </span><span class="s4">0x80</span>

<span class="s1">CU_CTX_FLAGS_MASK </span><span class="s3">= </span><span class="s4">0xff</span>


<span class="s2"># DEFINES</span>

<span class="s2"># If set, host memory is portable between CUDA contexts.</span>
<span class="s2"># Flag for cuMemHostAlloc()</span>
<span class="s1">CU_MEMHOSTALLOC_PORTABLE </span><span class="s3">= </span><span class="s4">0x01</span>

<span class="s2"># If set, host memory is mapped into CUDA address space and</span>
<span class="s2"># cuMemHostGetDevicePointer() may be called on the host pointer.</span>
<span class="s2"># Flag for cuMemHostAlloc()</span>
<span class="s1">CU_MEMHOSTALLOC_DEVICEMAP </span><span class="s3">= </span><span class="s4">0x02</span>

<span class="s2"># If set, host memory is allocated as write-combined - fast to write,</span>
<span class="s2"># faster to DMA, slow to read except via SSE4 streaming load instruction</span>
<span class="s2"># (MOVNTDQA).</span>
<span class="s2"># Flag for cuMemHostAlloc()</span>
<span class="s1">CU_MEMHOSTALLOC_WRITECOMBINED </span><span class="s3">= </span><span class="s4">0x04</span>


<span class="s2"># If set, host memory is portable between CUDA contexts.</span>
<span class="s2"># Flag for cuMemHostRegister()</span>
<span class="s1">CU_MEMHOSTREGISTER_PORTABLE </span><span class="s3">= </span><span class="s4">0x01</span>

<span class="s2"># If set, host memory is mapped into CUDA address space and</span>
<span class="s2"># cuMemHostGetDevicePointer() may be called on the host pointer.</span>
<span class="s2"># Flag for cuMemHostRegister()</span>
<span class="s1">CU_MEMHOSTREGISTER_DEVICEMAP </span><span class="s3">= </span><span class="s4">0x02</span>

<span class="s2"># If set, the passed memory pointer is treated as pointing to some</span>
<span class="s2"># memory-mapped I/O space, e.g. belonging to a third-party PCIe device.</span>
<span class="s2"># On Windows the flag is a no-op. On Linux that memory is marked</span>
<span class="s2"># as non cache-coherent for the GPU and is expected</span>
<span class="s2"># to be physically contiguous. It may return CUDA_ERROR_NOT_PERMITTED</span>
<span class="s2"># if run as an unprivileged user, CUDA_ERROR_NOT_SUPPORTED on older</span>
<span class="s2"># Linux kernel versions. On all other platforms, it is not supported</span>
<span class="s2"># and CUDA_ERROR_NOT_SUPPORTED is returned.</span>
<span class="s2"># Flag for cuMemHostRegister()</span>
<span class="s1">CU_MEMHOSTREGISTER_IOMEMORY </span><span class="s3">= </span><span class="s4">0x04</span>

<span class="s2"># If set, the passed memory pointer is treated as pointing to memory</span>
<span class="s2"># that is considered read-only by the device. On platforms without</span>
<span class="s2"># CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,</span>
<span class="s2"># this flag is required in order to register memory mapped</span>
<span class="s2"># to the CPU as read-only. Support for the use of this flag can be</span>
<span class="s2"># queried from the device attribute</span>
<span class="s2"># CU_DEVICE_ATTRIBUTE_READ_ONLY_HOST_REGISTER_SUPPORTED.</span>
<span class="s2"># Using this flag with a current context associated with a device</span>
<span class="s2"># that does not have this attribute set will cause cuMemHostRegister</span>
<span class="s2"># to error with CUDA_ERROR_NOT_SUPPORTED.</span>
<span class="s1">CU_MEMHOSTREGISTER_READ_ONLY </span><span class="s3">= </span><span class="s4">0x08</span>


<span class="s2"># CUDA Mem Attach Flags</span>

<span class="s2"># If set, managed memory is accessible from all streams on all devices.</span>
<span class="s1">CU_MEM_ATTACH_GLOBAL </span><span class="s3">= </span><span class="s4">0x01</span>

<span class="s2"># If set on a platform where the device attribute</span>
<span class="s2"># cudaDevAttrConcurrentManagedAccess is zero, then managed memory is</span>
<span class="s2"># only accessible on the host (unless explicitly attached to a stream</span>
<span class="s2"># with cudaStreamAttachMemAsync, in which case it can be used in kernels</span>
<span class="s2"># launched on that stream).</span>
<span class="s1">CU_MEM_ATTACH_HOST </span><span class="s3">= </span><span class="s4">0x02</span>

<span class="s2"># If set on a platform where the device attribute</span>
<span class="s2"># cudaDevAttrConcurrentManagedAccess is zero, then managed memory accesses</span>
<span class="s2"># on the associated device must only be from a single stream.</span>
<span class="s1">CU_MEM_ATTACH_SINGLE </span><span class="s3">= </span><span class="s4">0x04</span>


<span class="s2"># Event creation flags</span>

<span class="s2"># Default event flag</span>
<span class="s1">CU_EVENT_DEFAULT </span><span class="s3">= </span><span class="s4">0x0</span>
<span class="s2"># Event uses blocking synchronization</span>
<span class="s1">CU_EVENT_BLOCKING_SYNC </span><span class="s3">= </span><span class="s4">0x1</span>
<span class="s2"># Event will not record timing data</span>
<span class="s1">CU_EVENT_DISABLE_TIMING </span><span class="s3">= </span><span class="s4">0x2</span>
<span class="s2"># Event is suitable for interprocess use. CU_EVENT_DISABLE_TIMING must be set</span>
<span class="s1">CU_EVENT_INTERPROCESS </span><span class="s3">= </span><span class="s4">0x4</span>


<span class="s2"># Pointer information</span>

<span class="s2"># The CUcontext on which a pointer was allocated or registered</span>
<span class="s1">CU_POINTER_ATTRIBUTE_CONTEXT </span><span class="s3">= </span><span class="s4">1</span>
<span class="s2"># The CUmemorytype describing the physical location of a pointer</span>
<span class="s1">CU_POINTER_ATTRIBUTE_MEMORY_TYPE </span><span class="s3">= </span><span class="s4">2</span>
<span class="s2"># The address at which a pointer's memory may be accessed on the device</span>
<span class="s1">CU_POINTER_ATTRIBUTE_DEVICE_POINTER </span><span class="s3">= </span><span class="s4">3</span>
<span class="s2"># The address at which a pointer's memory may be accessed on the host</span>
<span class="s1">CU_POINTER_ATTRIBUTE_HOST_POINTER </span><span class="s3">= </span><span class="s4">4</span>
<span class="s2"># A pair of tokens for use with the nv-p2p.h Linux kernel interface</span>
<span class="s1">CU_POINTER_ATTRIBUTE_P2P_TOKENS </span><span class="s3">= </span><span class="s4">5</span>
<span class="s2"># Synchronize every synchronous memory operation initiated on this region</span>
<span class="s1">CU_POINTER_ATTRIBUTE_SYNC_MEMOPS </span><span class="s3">= </span><span class="s4">6</span>
<span class="s2"># A process-wide unique ID for an allocated memory region</span>
<span class="s1">CU_POINTER_ATTRIBUTE_BUFFER_ID </span><span class="s3">= </span><span class="s4">7</span>
<span class="s2"># Indicates if the pointer points to managed memory</span>
<span class="s1">CU_POINTER_ATTRIBUTE_IS_MANAGED </span><span class="s3">= </span><span class="s4">8</span>
<span class="s2"># A device ordinal of a device on which a pointer was allocated or registered</span>
<span class="s1">CU_POINTER_ATTRIBUTE_DEVICE_ORDINAL </span><span class="s3">= </span><span class="s4">9</span>
<span class="s2"># 1 if this pointer maps to an allocation</span>
<span class="s2"># that is suitable for cudaIpcGetMemHandle, 0 otherwise</span>
<span class="s1">CU_POINTER_ATTRIBUTE_IS_LEGACY_CUDA_IPC_CAPABLE </span><span class="s3">= </span><span class="s4">10</span>
<span class="s2"># Starting address for this requested pointer</span>
<span class="s1">CU_POINTER_ATTRIBUTE_RANGE_START_ADDR </span><span class="s3">= </span><span class="s4">11</span>
<span class="s2"># Size of the address range for this requested pointer</span>
<span class="s1">CU_POINTER_ATTRIBUTE_RANGE_SIZE </span><span class="s3">= </span><span class="s4">12</span>
<span class="s2"># 1 if this pointer is in a valid address range</span>
<span class="s2"># that is mapped to a backing allocation, 0 otherwise</span>
<span class="s1">CU_POINTER_ATTRIBUTE_MAPPED </span><span class="s3">= </span><span class="s4">13</span>
<span class="s2"># Bitmask of allowed CUmemAllocationHandleType for this allocation</span>
<span class="s1">CU_POINTER_ATTRIBUTE_ALLOWED_HANDLE_TYPES </span><span class="s3">= </span><span class="s4">14</span>
<span class="s2"># 1 if the memory this pointer is referencing</span>
<span class="s2"># can be used with the GPUDirect RDMA API</span>
<span class="s1">CU_POINTER_ATTRIBUTE_IS_GPU_DIRECT_RDMA_CAPABLE </span><span class="s3">= </span><span class="s4">15</span>
<span class="s2"># Returns the access flags the device associated</span>
<span class="s2"># with the current context has on the corresponding</span>
<span class="s2"># memory referenced by the pointer given</span>
<span class="s1">CU_POINTER_ATTRIBUTE_ACCESS_FLAGS </span><span class="s3">= </span><span class="s4">16</span>
<span class="s2"># Returns the mempool handle for the allocation</span>
<span class="s2"># if it was allocated from a mempool. Otherwise returns NULL</span>
<span class="s1">CU_POINTER_ATTRIBUTE_MEMPOOL_HANDLE </span><span class="s3">= </span><span class="s4">17</span>
<span class="s2"># Size of the actual underlying mapping that the pointer belongs to</span>
<span class="s1">CU_POINTER_ATTRIBUTE_MAPPING_SIZE </span><span class="s3">= </span><span class="s4">18</span>
<span class="s2"># The start address of the mapping that the pointer belongs to</span>
<span class="s1">CU_POINTER_ATTRIBUTE_MAPPING_BASE_ADDR </span><span class="s3">= </span><span class="s4">19</span>
<span class="s2"># A process-wide unique id corresponding to the</span>
<span class="s2"># physical allocation the pointer belongs to</span>
<span class="s1">CU_POINTER_ATTRIBUTE_MEMORY_BLOCK_ID </span><span class="s3">= </span><span class="s4">20</span>


<span class="s2"># Memory types</span>

<span class="s2"># Host memory</span>
<span class="s1">CU_MEMORYTYPE_HOST </span><span class="s3">= </span><span class="s4">0x01</span>
<span class="s2"># Device memory</span>
<span class="s1">CU_MEMORYTYPE_DEVICE </span><span class="s3">= </span><span class="s4">0x02</span>
<span class="s2"># Array memory</span>
<span class="s1">CU_MEMORYTYPE_ARRAY </span><span class="s3">= </span><span class="s4">0x03</span>
<span class="s2"># Unified device or host memory</span>
<span class="s1">CU_MEMORYTYPE_UNIFIED </span><span class="s3">= </span><span class="s4">0x04</span>


<span class="s2"># Device code formats</span>

<span class="s2"># Compiled device-class-specific device code</span>
<span class="s2"># Applicable options: none</span>
<span class="s1">CU_JIT_INPUT_CUBIN </span><span class="s3">= </span><span class="s4">0</span>

<span class="s2"># PTX source code</span>
<span class="s2"># Applicable options: PTX compiler options</span>
<span class="s1">CU_JIT_INPUT_PTX </span><span class="s3">= </span><span class="s4">1</span>

<span class="s2"># Bundle of multiple cubins and/or PTX of some device code</span>
<span class="s2"># Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY</span>
<span class="s1">CU_JIT_INPUT_FATBINARY </span><span class="s3">= </span><span class="s4">2</span>

<span class="s2"># Host object with embedded device code</span>
<span class="s2"># Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY</span>
<span class="s1">CU_JIT_INPUT_OBJECT </span><span class="s3">= </span><span class="s4">3</span>

<span class="s2"># Archive of host objects with embedded device code</span>
<span class="s2"># Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY</span>
<span class="s1">CU_JIT_INPUT_LIBRARY </span><span class="s3">= </span><span class="s4">4</span>

<span class="s1">CU_JIT_NUM_INPUT_TYPES </span><span class="s3">= </span><span class="s4">6</span>


<span class="s2"># Online compiler and linker options</span>

<span class="s2"># Max number of registers that a thread may use.</span>
<span class="s2"># Option type: unsigned int</span>
<span class="s2"># Applies to: compiler only</span>
<span class="s1">CU_JIT_MAX_REGISTERS </span><span class="s3">= </span><span class="s4">0</span>

<span class="s2"># IN: Specifies minimum number of threads per block to target compilation</span>
<span class="s2"># for</span>
<span class="s2"># OUT: Returns the number of threads the compiler actually targeted.</span>
<span class="s2"># This restricts the resource utilization fo the compiler (e.g. max</span>
<span class="s2"># registers) such that a block with the given number of threads should be</span>
<span class="s2"># able to launch based on register limitations. Note, this option does not</span>
<span class="s2"># currently take into account any other resource limitations, such as</span>
<span class="s2"># shared memory utilization.</span>
<span class="s2"># Cannot be combined with ::CU_JIT_TARGET.</span>
<span class="s2"># Option type: unsigned int</span>
<span class="s2"># Applies to: compiler only</span>
<span class="s1">CU_JIT_THREADS_PER_BLOCK </span><span class="s3">= </span><span class="s4">1</span>

<span class="s2"># Overwrites the option value with the total wall clock time, in</span>
<span class="s2"># milliseconds, spent in the compiler and linker</span>
<span class="s2"># Option type: float</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_WALL_TIME </span><span class="s3">= </span><span class="s4">2</span>

<span class="s2"># Pointer to a buffer in which to print any log messages</span>
<span class="s2"># that are informational in nature (the buffer size is specified via</span>
<span class="s2"># option ::CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES)</span>
<span class="s2"># Option type: char *</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_INFO_LOG_BUFFER </span><span class="s3">= </span><span class="s4">3</span>

<span class="s2"># IN: Log buffer size in bytes.  Log messages will be capped at this size</span>
<span class="s2"># (including null terminator)</span>
<span class="s2"># OUT: Amount of log buffer filled with messages</span>
<span class="s2"># Option type: unsigned int</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES </span><span class="s3">= </span><span class="s4">4</span>

<span class="s2"># Pointer to a buffer in which to print any log messages that</span>
<span class="s2"># reflect errors (the buffer size is specified via option</span>
<span class="s2"># ::CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES)</span>
<span class="s2"># Option type: char *</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_ERROR_LOG_BUFFER </span><span class="s3">= </span><span class="s4">5</span>

<span class="s2"># IN: Log buffer size in bytes.  Log messages will be capped at this size</span>
<span class="s2"># (including null terminator)</span>
<span class="s2"># OUT: Amount of log buffer filled with messages</span>
<span class="s2"># Option type: unsigned int</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES </span><span class="s3">= </span><span class="s4">6</span>

<span class="s2"># Level of optimizations to apply to generated code (0 - 4), with 4</span>
<span class="s2"># being the default and highest level of optimizations.</span>
<span class="s2"># Option type: unsigned int</span>
<span class="s2"># Applies to: compiler only</span>
<span class="s1">CU_JIT_OPTIMIZATION_LEVEL </span><span class="s3">= </span><span class="s4">7</span>

<span class="s2"># No option value required. Determines the target based on the current</span>
<span class="s2"># attached context (default)</span>
<span class="s2"># Option type: No option value needed</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_TARGET_FROM_CUCONTEXT </span><span class="s3">= </span><span class="s4">8</span>

<span class="s2"># Target is chosen based on supplied ::CUjit_target.  Cannot be</span>
<span class="s2"># combined with ::CU_JIT_THREADS_PER_BLOCK.</span>
<span class="s2"># Option type: unsigned int for enumerated type ::CUjit_target</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_TARGET </span><span class="s3">= </span><span class="s4">9</span>

<span class="s2"># Specifies choice of fallback strategy if matching cubin is not found.</span>
<span class="s2"># Choice is based on supplied ::CUjit_fallback.</span>
<span class="s2"># Option type: unsigned int for enumerated type ::CUjit_fallback</span>
<span class="s2"># Applies to: compiler only</span>
<span class="s1">CU_JIT_FALLBACK_STRATEGY </span><span class="s3">= </span><span class="s4">10</span>

<span class="s2"># Specifies whether to create debug information in output (-g)</span>
<span class="s2"># (0: false, default)</span>
<span class="s2"># Option type: int</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_GENERATE_DEBUG_INFO </span><span class="s3">= </span><span class="s4">11</span>

<span class="s2"># Generate verbose log messages (0: false, default)</span>
<span class="s2"># Option type: int</span>
<span class="s2"># Applies to: compiler and linker</span>
<span class="s1">CU_JIT_LOG_VERBOSE </span><span class="s3">= </span><span class="s4">12</span>

<span class="s2"># Generate line number information (-lineinfo) (0: false, default)</span>
<span class="s2"># Option type: int</span>
<span class="s2"># Applies to: compiler only</span>
<span class="s1">CU_JIT_GENERATE_LINE_INFO </span><span class="s3">= </span><span class="s4">13</span>

<span class="s2"># Specifies whether to enable caching explicitly (-dlcm)</span>
<span class="s2"># Choice is based on supplied ::CUjit_cacheMode_enum.</span>
<span class="s2"># Option type: unsigned int for enumerated type ::CUjit_cacheMode_enum</span>
<span class="s2"># Applies to: compiler only</span>
<span class="s1">CU_JIT_CACHE_MODE </span><span class="s3">= </span><span class="s4">14</span>


<span class="s2"># CUfunction_attribute</span>

<span class="s2"># The maximum number of threads per block, beyond which a launch of the</span>
<span class="s2"># function would fail. This number depends on both the function and the</span>
<span class="s2"># device on which the function is currently loaded.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK </span><span class="s3">= </span><span class="s4">0</span>

<span class="s2"># The size in bytes of statically-allocated shared memory required by</span>
<span class="s2"># this function. This does not include dynamically-allocated shared</span>
<span class="s2"># memory requested by the user at runtime.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES </span><span class="s3">= </span><span class="s4">1</span>

<span class="s2"># The size in bytes of user-allocated constant memory required by this</span>
<span class="s2"># function.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES </span><span class="s3">= </span><span class="s4">2</span>

<span class="s2"># The size in bytes of local memory used by each thread of this function.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES </span><span class="s3">= </span><span class="s4">3</span>

<span class="s2"># The number of registers used by each thread of this function.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_NUM_REGS </span><span class="s3">= </span><span class="s4">4</span>

<span class="s2"># The PTX virtual architecture version for which the function was</span>
<span class="s2"># compiled. This value is the major PTX version * 10 + the minor PTX</span>
<span class="s2"># version, so a PTX version 1.3 function would return the value 13.</span>
<span class="s2"># Note that this may return the undefined value of 0 for cubins</span>
<span class="s2"># compiled prior to CUDA 3.0.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_PTX_VERSION </span><span class="s3">= </span><span class="s4">5</span>

<span class="s2"># The binary architecture version for which the function was compiled.</span>
<span class="s2"># This value is the major binary version * 10 + the minor binary version,</span>
<span class="s2"># so a binary version 1.3 function would return the value 13. Note that</span>
<span class="s2"># this will return a value of 10 for legacy cubins that do not have a</span>
<span class="s2"># properly-encoded binary architecture version.</span>
<span class="s1">CU_FUNC_ATTRIBUTE_BINARY_VERSION </span><span class="s3">= </span><span class="s4">6</span>

<span class="s2"># The attribute to indicate whether the function has been compiled</span>
<span class="s2"># with user specified option &quot;-Xptxas --dlcm=ca&quot; set</span>
<span class="s1">CU_FUNC_ATTRIBUTE_CACHE_MODE_CA </span><span class="s3">= </span><span class="s4">7</span>

<span class="s2"># The maximum size in bytes of dynamically-allocated shared memory</span>
<span class="s2"># that can be used by this function. If the user-specified</span>
<span class="s2"># dynamic shared memory size is larger than this value,</span>
<span class="s2"># the launch will fail. See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES </span><span class="s3">= </span><span class="s4">8</span>

<span class="s2"># On devices where the L1 cache and shared memory use the same</span>
<span class="s2"># hardware resources, this sets the shared memory carveout preference,</span>
<span class="s2"># in percent of the total shared memory. Refer to</span>
<span class="s2"># CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR.</span>
<span class="s2"># This is only a hint, and the driver can choose a different ratio</span>
<span class="s2"># if required to execute the function.</span>
<span class="s2"># See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_PREFERRED_SHARED_MEMORY_CARVEOUT </span><span class="s3">= </span><span class="s4">9</span>

<span class="s2"># If this attribute is set, the kernel must launch with a valid cluster</span>
<span class="s2"># size specified. See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_CLUSTER_SIZE_MUST_BE_SET </span><span class="s3">= </span><span class="s4">10</span>

<span class="s2"># The required cluster width in blocks. The values must either all be 0</span>
<span class="s2"># or all be positive. The validity of the cluster dimensions</span>
<span class="s2"># is otherwise checked at launch time. If the value is set during</span>
<span class="s2"># compile time, it cannot be set at runtime.</span>
<span class="s2"># Setting it at runtime will return CUDA_ERROR_NOT_PERMITTED.</span>
<span class="s2"># See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_REQUIRED_CLUSTER_WIDTH </span><span class="s3">= </span><span class="s4">11</span>

<span class="s2"># The required cluster height in blocks. The values must either all be 0</span>
<span class="s2"># or all be positive. The validity of the cluster dimensions</span>
<span class="s2"># is otherwise checked at launch time.If the value is set during</span>
<span class="s2"># compile time, it cannot be set at runtime.</span>
<span class="s2"># Setting it at runtime should return CUDA_ERROR_NOT_PERMITTED.</span>
<span class="s2"># See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_REQUIRED_CLUSTER_HEIGHT </span><span class="s3">= </span><span class="s4">12</span>

<span class="s2"># The required cluster depth in blocks. The values must either all be 0</span>
<span class="s2"># or all be positive. The validity of the cluster dimensions</span>
<span class="s2"># is otherwise checked at launch time.If the value is set during</span>
<span class="s2"># compile time, it cannot be set at runtime.</span>
<span class="s2"># Setting it at runtime should return CUDA_ERROR_NOT_PERMITTED.</span>
<span class="s2"># See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_REQUIRED_CLUSTER_DEPTH </span><span class="s3">= </span><span class="s4">13</span>

<span class="s2"># Whether the function can be launched with non-portable cluster size.</span>
<span class="s2"># 1 is allowed, 0 is disallowed. A non-portable cluster size may only</span>
<span class="s2"># function on the specific SKUs the program is tested on.</span>
<span class="s2"># The launch might fail if the program is run on a different hardware platform.</span>
<span class="s2"># For more details refer to link :</span>
<span class="s2"># https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES</span>
<span class="s1">CU_FUNC_ATTRIBUTE_NON_PORTABLE_CLUSTER_SIZE_ALLOWED </span><span class="s3">= </span><span class="s4">14</span>

<span class="s2"># The block scheduling policy of a function.</span>
<span class="s2"># The value type is CUclusterSchedulingPolicy / cudaClusterSchedulingPolicy.</span>
<span class="s2"># See cuFuncSetAttribute, cuKernelSetAttribute</span>
<span class="s1">CU_FUNC_ATTRIBUTE_CLUSTER_SCHEDULING_POLICY_PREFERENCE </span><span class="s3">= </span><span class="s4">15</span>


<span class="s2"># Device attributes</span>

<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK </span><span class="s3">= </span><span class="s4">1</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X </span><span class="s3">= </span><span class="s4">2</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y </span><span class="s3">= </span><span class="s4">3</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z </span><span class="s3">= </span><span class="s4">4</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X </span><span class="s3">= </span><span class="s4">5</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y </span><span class="s3">= </span><span class="s4">6</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z </span><span class="s3">= </span><span class="s4">7</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK </span><span class="s3">= </span><span class="s4">8</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY </span><span class="s3">= </span><span class="s4">9</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_WARP_SIZE </span><span class="s3">= </span><span class="s4">10</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_PITCH </span><span class="s3">= </span><span class="s4">11</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK </span><span class="s3">= </span><span class="s4">12</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_CLOCK_RATE </span><span class="s3">= </span><span class="s4">13</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT </span><span class="s3">= </span><span class="s4">14</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_GPU_OVERLAP </span><span class="s3">= </span><span class="s4">15</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT </span><span class="s3">= </span><span class="s4">16</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT </span><span class="s3">= </span><span class="s4">17</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_INTEGRATED </span><span class="s3">= </span><span class="s4">18</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY </span><span class="s3">= </span><span class="s4">19</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_COMPUTE_MODE </span><span class="s3">= </span><span class="s4">20</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_1D_WIDTH </span><span class="s3">= </span><span class="s4">21</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_WIDTH </span><span class="s3">= </span><span class="s4">22</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_HEIGHT </span><span class="s3">= </span><span class="s4">23</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_3D_WIDTH </span><span class="s3">= </span><span class="s4">24</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_3D_HEIGHT </span><span class="s3">= </span><span class="s4">25</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_3D_DEPTH </span><span class="s3">= </span><span class="s4">26</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_LAYERED_WIDTH </span><span class="s3">= </span><span class="s4">27</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_LAYERED_HEIGHT </span><span class="s3">= </span><span class="s4">28</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_LAYERED_LAYERS </span><span class="s3">= </span><span class="s4">29</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_SURFACE_ALIGNMENT </span><span class="s3">= </span><span class="s4">30</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS </span><span class="s3">= </span><span class="s4">31</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_ECC_ENABLED </span><span class="s3">= </span><span class="s4">32</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_PCI_BUS_ID </span><span class="s3">= </span><span class="s4">33</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID </span><span class="s3">= </span><span class="s4">34</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_TCC_DRIVER </span><span class="s3">= </span><span class="s4">35</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE </span><span class="s3">= </span><span class="s4">36</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH </span><span class="s3">= </span><span class="s4">37</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE </span><span class="s3">= </span><span class="s4">38</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTI_PROCESSOR </span><span class="s3">= </span><span class="s4">39</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_ASYNC_ENGINE_COUNT </span><span class="s3">= </span><span class="s4">40</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING </span><span class="s3">= </span><span class="s4">41</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_1D_LAYERED_WIDTH </span><span class="s3">= </span><span class="s4">42</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_1D_LAYERED_LAYERS </span><span class="s3">= </span><span class="s4">43</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_GATHER_WIDTH </span><span class="s3">= </span><span class="s4">45</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_GATHER_HEIGHT </span><span class="s3">= </span><span class="s4">46</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_3D_WIDTH_ALT </span><span class="s3">= </span><span class="s4">47</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_3D_HEIGHT_ALT </span><span class="s3">= </span><span class="s4">48</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_3D_DEPTH_ALT </span><span class="s3">= </span><span class="s4">49</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_PCI_DOMAIN_ID </span><span class="s3">= </span><span class="s4">50</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT </span><span class="s3">= </span><span class="s4">51</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_CUBEMAP_WIDTH </span><span class="s3">= </span><span class="s4">52</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_CUBEMAP_LAYERED_WIDTH </span><span class="s3">= </span><span class="s4">53</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_CUBEMAP_LAYERED_LAYERS </span><span class="s3">= </span><span class="s4">54</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_1D_WIDTH </span><span class="s3">= </span><span class="s4">55</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_2D_WIDTH </span><span class="s3">= </span><span class="s4">56</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_2D_HEIGHT </span><span class="s3">= </span><span class="s4">57</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_3D_WIDTH </span><span class="s3">= </span><span class="s4">58</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_3D_HEIGHT </span><span class="s3">= </span><span class="s4">59</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_3D_DEPTH </span><span class="s3">= </span><span class="s4">60</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_1D_LAYERED_WIDTH </span><span class="s3">= </span><span class="s4">61</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_1D_LAYERED_LAYERS </span><span class="s3">= </span><span class="s4">62</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_2D_LAYERED_WIDTH </span><span class="s3">= </span><span class="s4">63</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_2D_LAYERED_HEIGHT </span><span class="s3">= </span><span class="s4">64</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_2D_LAYERED_LAYERS </span><span class="s3">= </span><span class="s4">65</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_CUBEMAP_WIDTH </span><span class="s3">= </span><span class="s4">66</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_CUBEMAP_LAYERED_WIDTH </span><span class="s3">= </span><span class="s4">67</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SURFACE_CUBEMAP_LAYERED_LAYERS </span><span class="s3">= </span><span class="s4">68</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_1D_LINEAR_WIDTH </span><span class="s3">= </span><span class="s4">69</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_LINEAR_WIDTH </span><span class="s3">= </span><span class="s4">70</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_LINEAR_HEIGHT </span><span class="s3">= </span><span class="s4">71</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_LINEAR_PITCH </span><span class="s3">= </span><span class="s4">72</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_2D_MIPMAPPED_WIDTH </span><span class="s3">= </span><span class="s4">73</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_MAX_TEXTURE_2D_MIPMAPPED_HEIGHT </span><span class="s3">= </span><span class="s4">74</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR </span><span class="s3">= </span><span class="s4">75</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR </span><span class="s3">= </span><span class="s4">76</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_TEXTURE_1D_MIPMAPPED_WIDTH </span><span class="s3">= </span><span class="s4">77</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_STREAM_PRIORITIES_SUPPORTED </span><span class="s3">= </span><span class="s4">78</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED </span><span class="s3">= </span><span class="s4">79</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED </span><span class="s3">= </span><span class="s4">80</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR </span><span class="s3">= </span><span class="s4">81</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR </span><span class="s3">= </span><span class="s4">82</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY </span><span class="s3">= </span><span class="s4">83</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_IS_MULTI_GPU_BOARD </span><span class="s3">= </span><span class="s4">84</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID </span><span class="s3">= </span><span class="s4">85</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED </span><span class="s3">= </span><span class="s4">86</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO </span><span class="s3">= </span><span class="s4">87</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS </span><span class="s3">= </span><span class="s4">88</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS </span><span class="s3">= </span><span class="s4">89</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED </span><span class="s3">= </span><span class="s4">90</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM </span><span class="s3">= </span><span class="s4">91</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_COOPERATIVE_LAUNCH </span><span class="s3">= </span><span class="s4">95</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_COOPERATIVE_MULTI_DEVICE_LAUNCH </span><span class="s3">= </span><span class="s4">96</span>
<span class="s1">CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN </span><span class="s3">= </span><span class="s4">97</span>
</pre>
</body>
</html>