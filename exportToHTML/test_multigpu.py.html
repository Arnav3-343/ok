<html>
<head>
<title>test_multigpu.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #2aacb8;}
.s4 { color: #6aab73;}
.s5 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_multigpu.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">numba </span><span class="s0">import </span><span class="s1">cuda</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numba</span><span class="s2">.</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">testing </span><span class="s0">import </span><span class="s1">skip_on_cudasim</span><span class="s2">, </span><span class="s1">CUDATestCase</span>
<span class="s0">import </span><span class="s1">threading</span>
<span class="s0">import </span><span class="s1">unittest</span>


<span class="s0">class </span><span class="s1">TestMultiGPUContext</span><span class="s2">(</span><span class="s1">CUDATestCase</span><span class="s2">):</span>
    <span class="s2">@</span><span class="s1">unittest</span><span class="s2">.</span><span class="s1">skipIf</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">) &lt; </span><span class="s3">2</span><span class="s2">, </span><span class="s4">&quot;need more than 1 gpus&quot;</span><span class="s2">)</span>
    <span class="s0">def </span><span class="s1">test_multigpu_context</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s2">@</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">jit</span><span class="s2">(</span><span class="s4">&quot;void(float64[:], float64[:])&quot;</span><span class="s2">)</span>
        <span class="s0">def </span><span class="s1">copy_plus_1</span><span class="s2">(</span><span class="s1">inp</span><span class="s2">, </span><span class="s1">out</span><span class="s2">):</span>
            <span class="s1">i </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">grid</span><span class="s2">(</span><span class="s3">1</span><span class="s2">)</span>
            <span class="s0">if </span><span class="s1">i </span><span class="s2">&lt; </span><span class="s1">out</span><span class="s2">.</span><span class="s1">size</span><span class="s2">:</span>
                <span class="s1">out</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] = </span><span class="s1">inp</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] + </span><span class="s3">1</span>

        <span class="s0">def </span><span class="s1">check</span><span class="s2">(</span><span class="s1">inp</span><span class="s2">, </span><span class="s1">out</span><span class="s2">):</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">testing</span><span class="s2">.</span><span class="s1">assert_equal</span><span class="s2">(</span><span class="s1">inp </span><span class="s2">+ </span><span class="s3">1</span><span class="s2">, </span><span class="s1">out</span><span class="s2">)</span>

        <span class="s1">N </span><span class="s2">= </span><span class="s3">32</span>
        <span class="s1">A </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
        <span class="s1">B </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">copy_plus_1</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s1">N</span><span class="s2">](</span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">)</span>

        <span class="s1">check</span><span class="s2">(</span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">)</span>

        <span class="s1">copy_plus_1</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s1">N</span><span class="s2">](</span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">)</span>
        <span class="s1">check</span><span class="s2">(</span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">A0 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
            <span class="s1">B0 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
            <span class="s1">copy_plus_1</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s1">N</span><span class="s2">](</span><span class="s1">A0</span><span class="s2">, </span><span class="s1">B0</span><span class="s2">)</span>

            <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">1</span><span class="s2">]:</span>
                <span class="s1">A1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
                <span class="s1">B1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
                <span class="s1">copy_plus_1</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s1">N</span><span class="s2">](</span><span class="s1">A1</span><span class="s2">, </span><span class="s1">B1</span><span class="s2">)</span>

        <span class="s1">check</span><span class="s2">(</span><span class="s1">A0</span><span class="s2">, </span><span class="s1">B0</span><span class="s2">)</span>
        <span class="s1">check</span><span class="s2">(</span><span class="s1">A1</span><span class="s2">, </span><span class="s1">B1</span><span class="s2">)</span>

        <span class="s1">A </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
        <span class="s1">B </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">N</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
        <span class="s1">copy_plus_1</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s1">N</span><span class="s2">](</span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">)</span>
        <span class="s1">check</span><span class="s2">(</span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">)</span>

    <span class="s2">@</span><span class="s1">skip_on_cudasim</span><span class="s2">(</span><span class="s4">'Simulator does not support multiple threads'</span><span class="s2">)</span>
    <span class="s0">def </span><span class="s1">test_multithreaded</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s0">def </span><span class="s1">work</span><span class="s2">(</span><span class="s1">gpu</span><span class="s2">, </span><span class="s1">dA</span><span class="s2">, </span><span class="s1">results</span><span class="s2">, </span><span class="s1">ridx</span><span class="s2">):</span>
            <span class="s0">try</span><span class="s2">:</span>
                <span class="s0">with </span><span class="s1">gpu</span><span class="s2">:</span>
                    <span class="s1">arr </span><span class="s2">= </span><span class="s1">dA</span><span class="s2">.</span><span class="s1">copy_to_host</span><span class="s2">()</span>

            <span class="s0">except </span><span class="s1">Exception </span><span class="s0">as </span><span class="s1">e</span><span class="s2">:</span>
                <span class="s1">results</span><span class="s2">[</span><span class="s1">ridx</span><span class="s2">] = </span><span class="s1">e</span>

            <span class="s0">else</span><span class="s2">:</span>
                <span class="s1">results</span><span class="s2">[</span><span class="s1">ridx</span><span class="s2">] = </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">arr </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s3">10</span><span class="s2">))</span>

        <span class="s1">dA </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">to_device</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s3">10</span><span class="s2">))</span>

        <span class="s1">nthreads </span><span class="s2">= </span><span class="s3">10</span>
        <span class="s1">results </span><span class="s2">= [</span><span class="s0">None</span><span class="s2">] * </span><span class="s1">nthreads</span>
        <span class="s1">threads </span><span class="s2">= [</span><span class="s1">threading</span><span class="s2">.</span><span class="s1">Thread</span><span class="s2">(</span><span class="s1">target</span><span class="s2">=</span><span class="s1">work</span><span class="s2">, </span><span class="s1">args</span><span class="s2">=(</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">.</span><span class="s1">current</span><span class="s2">,</span>
                                                       <span class="s1">dA</span><span class="s2">, </span><span class="s1">results</span><span class="s2">, </span><span class="s1">i</span><span class="s2">))</span>
                   <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">nthreads</span><span class="s2">)]</span>
        <span class="s0">for </span><span class="s1">th </span><span class="s0">in </span><span class="s1">threads</span><span class="s2">:</span>
            <span class="s1">th</span><span class="s2">.</span><span class="s1">start</span><span class="s2">()</span>

        <span class="s0">for </span><span class="s1">th </span><span class="s0">in </span><span class="s1">threads</span><span class="s2">:</span>
            <span class="s1">th</span><span class="s2">.</span><span class="s1">join</span><span class="s2">()</span>

        <span class="s0">for </span><span class="s1">r </span><span class="s0">in </span><span class="s1">results</span><span class="s2">:</span>
            <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">r</span><span class="s2">, </span><span class="s1">BaseException</span><span class="s2">):</span>
                <span class="s0">raise </span><span class="s1">r</span>
            <span class="s0">else</span><span class="s2">:</span>
                <span class="s1">self</span><span class="s2">.</span><span class="s1">assertTrue</span><span class="s2">(</span><span class="s1">r</span><span class="s2">)</span>

    <span class="s2">@</span><span class="s1">unittest</span><span class="s2">.</span><span class="s1">skipIf</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">) &lt; </span><span class="s3">2</span><span class="s2">, </span><span class="s4">&quot;need more than 1 gpus&quot;</span><span class="s2">)</span>
    <span class="s0">def </span><span class="s1">test_with_context</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>

        <span class="s2">@</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">jit</span>
        <span class="s0">def </span><span class="s1">vector_add_scalar</span><span class="s2">(</span><span class="s1">arr</span><span class="s2">, </span><span class="s1">val</span><span class="s2">):</span>
            <span class="s1">i </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">grid</span><span class="s2">(</span><span class="s3">1</span><span class="s2">)</span>
            <span class="s0">if </span><span class="s1">i </span><span class="s2">&lt; </span><span class="s1">arr</span><span class="s2">.</span><span class="s1">size</span><span class="s2">:</span>
                <span class="s1">arr</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] += </span><span class="s1">val</span>

        <span class="s1">hostarr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s3">10</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">arr1 </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">to_device</span><span class="s2">(</span><span class="s1">hostarr</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">1</span><span class="s2">]:</span>
            <span class="s1">arr2 </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">to_device</span><span class="s2">(</span><span class="s1">hostarr</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">vector_add_scalar</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">10</span><span class="s2">](</span><span class="s1">arr1</span><span class="s2">, </span><span class="s3">1</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">1</span><span class="s2">]:</span>
            <span class="s1">vector_add_scalar</span><span class="s2">[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">10</span><span class="s2">](</span><span class="s1">arr2</span><span class="s2">, </span><span class="s3">2</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">testing</span><span class="s2">.</span><span class="s1">assert_equal</span><span class="s2">(</span><span class="s1">arr1</span><span class="s2">.</span><span class="s1">copy_to_host</span><span class="s2">(), (</span><span class="s1">hostarr </span><span class="s2">+ </span><span class="s3">1</span><span class="s2">))</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">1</span><span class="s2">]:</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">testing</span><span class="s2">.</span><span class="s1">assert_equal</span><span class="s2">(</span><span class="s1">arr2</span><span class="s2">.</span><span class="s1">copy_to_host</span><span class="s2">(), (</span><span class="s1">hostarr </span><span class="s2">+ </span><span class="s3">2</span><span class="s2">))</span>

    <span class="s2">@</span><span class="s1">unittest</span><span class="s2">.</span><span class="s1">skipIf</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">) &lt; </span><span class="s3">2</span><span class="s2">, </span><span class="s4">&quot;need more than 1 gpus&quot;</span><span class="s2">)</span>
    <span class="s0">def </span><span class="s1">test_with_context_peer_copy</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s5"># Peer access is not always possible - for example, with one GPU in TCC</span>
        <span class="s5"># mode and one in WDDM - if that is the case, this test would fail so</span>
        <span class="s5"># we need to skip it.</span>
        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">ctx </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">current_context</span><span class="s2">()</span>
            <span class="s0">if not </span><span class="s1">ctx</span><span class="s2">.</span><span class="s1">can_access_peer</span><span class="s2">(</span><span class="s3">1</span><span class="s2">):</span>
                <span class="s1">self</span><span class="s2">.</span><span class="s1">skipTest</span><span class="s2">(</span><span class="s4">'Peer access between GPUs disabled'</span><span class="s2">)</span>

        <span class="s5"># 1. Create a range in an array</span>
        <span class="s1">hostarr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s3">10</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>

        <span class="s5"># 2. Copy range array from host -&gt; GPU 0</span>
        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s1">arr1 </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">to_device</span><span class="s2">(</span><span class="s1">hostarr</span><span class="s2">)</span>

        <span class="s5"># 3. Initialize a zero-filled array on GPU 1</span>
        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">1</span><span class="s2">]:</span>
            <span class="s1">arr2 </span><span class="s2">= </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">to_device</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">hostarr</span><span class="s2">))</span>

        <span class="s0">with </span><span class="s1">cuda</span><span class="s2">.</span><span class="s1">gpus</span><span class="s2">[</span><span class="s3">0</span><span class="s2">]:</span>
            <span class="s5"># 4. Copy range from GPU 0 -&gt; GPU 1</span>
            <span class="s1">arr2</span><span class="s2">.</span><span class="s1">copy_to_device</span><span class="s2">(</span><span class="s1">arr1</span><span class="s2">)</span>

            <span class="s5"># 5. Copy range from GPU 1 -&gt; host and check contents</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">testing</span><span class="s2">.</span><span class="s1">assert_equal</span><span class="s2">(</span><span class="s1">arr2</span><span class="s2">.</span><span class="s1">copy_to_host</span><span class="s2">(), </span><span class="s1">hostarr</span><span class="s2">)</span>


<span class="s0">if </span><span class="s1">__name__ </span><span class="s2">== </span><span class="s4">'__main__'</span><span class="s2">:</span>
    <span class="s1">unittest</span><span class="s2">.</span><span class="s1">main</span><span class="s2">()</span>
</pre>
</body>
</html>